{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import config\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import data_analysis_for_paper as dafp\n",
    "\n",
    "sns.set_context(\"paper\")\n",
    "sns.set_style(\"ticks\")\n",
    "\n",
    "from collections import defaultdict\n",
    "current_pal = sns.color_palette()\n",
    "\n",
    "#%%\n",
    "def percentile(n):\n",
    "    def percentile_(x):\n",
    "        return np.percentile(x, n)\n",
    "    percentile_.__name__ = '%s%%' % n\n",
    "    return percentile_\n",
    "\n",
    "clean_lang = lambda x: x.replace(\"MergedCl\",\"\").replace(\"Cl\",\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%\n",
    "LANG_ORDER = [\"Rust\",\"JS\",\"Ruby\"]\n",
    "\n",
    "DATASETS = {}\n",
    "\n",
    "for lang in LANG_ORDER:\n",
    "    print lang\n",
    "\n",
    "    adoption_file = config.FINAL_DATA+\"cleaned_{0}_dependency_final.csv.gz\"\n",
    "    release_file = config.FINAL_DATA+\"cleaned_{0}_release_final.csv.gz\"\n",
    "    opts = {\"na_filter\": False}\n",
    "    #%%\n",
    "\n",
    "    df_adoption =  pd.read_csv(adoption_file.format(lang), **opts)\n",
    "    df_release =  pd.read_csv(release_file.format(lang), **opts)\n",
    "\n",
    "    df_fixed = pd.read_csv(config.WORKING_DATA+\"fixed_adopted_{0}_meta.csv\".format(lang), sep=\"\\t\",**opts)\n",
    "    df_fixed.loc[pd.isnull(df_fixed.orig_ver_string), \"orig_ver_string\"] = \"\"\n",
    "\n",
    "    #%%\n",
    "\n",
    "    df_fixed = df_fixed[df_fixed.commit_ts <= 1459468800]\n",
    "    df_fixed = df_fixed[df_fixed.release_ts_y <= 1459468800]\n",
    "\n",
    "    df_adoption = df_adoption[df_adoption.commit_ts <= 1459468800]\n",
    "    df_release = df_release[df_release.release_ts <= 1459468800]\n",
    "\n",
    "\n",
    "    df_fixed.loc[:,\"commit_ts\"] = pd.to_datetime(df_fixed.commit_ts, unit=\"s\")\n",
    "    df_fixed.loc[:,\"release_ts_y\"] = pd.to_datetime(df_fixed.release_ts_y, unit=\"s\")\n",
    "    df_adoption.loc[:,\"commit_ts\"] = pd.to_datetime(df_adoption.commit_ts, unit=\"s\")\n",
    "    df_release.loc[:,\"release_ts\"] = pd.to_datetime( df_release.release_ts, unit=\"s\")\n",
    "    \n",
    "    DATASETS[lang] = (df_fixed, df_adoption, df_release)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_df = []\n",
    "for lang in LANG_ORDER:\n",
    "    lang_ = lang.replace(\"MergedCl\",\"\").replace(\"Cl\",\"\")\n",
    "    (df_fixed, df_adoption, df_release) =   DATASETS[lang] \n",
    "\n",
    "    print \"\\nLang\", lang\n",
    "\n",
    "    rename_rules = {\"adopted_name\":\"project_name\", \"adopted_github\":\"project_github\"}\n",
    "\n",
    "    no_pub = df_release.query(\"is_published==1\")[[\"project_name\", \"project_github\"]].drop_duplicates().shape[0]\n",
    "    \n",
    "    no_gh_ = df_release.query(\"is_published==0\")[[\"project_name\", \"project_github\"]].drop_duplicates()\n",
    "    no_gh2_ =  df_fixed.query(\"is_published==0\")[[\"project_name\", \"project_github\"]].drop_duplicates()\n",
    "    \n",
    "    no_gh = pd.concat((no_gh_, no_gh2_)).drop_duplicates().shape[0]\n",
    "    \n",
    "    print \"\\nPublished projects\", no_pub\n",
    "    print \"non-Published projects\",no_gh\n",
    "    #print \"\\nadoption projects\", df_adoption[[\"project_name\", \"project_github\"]].drop_duplicates().shape\n",
    "\n",
    "\n",
    "    uniq_dep = df_fixed[[\"project_name\", \"project_github\"]].drop_duplicates()\n",
    "    uniq_dep_adopt = df_fixed[[\"adopted_name\", \"adopted_github\"]].drop_duplicates().rename(columns=rename_rules)\n",
    "    \n",
    "    no_total =  pd.concat([df_adoption[[\"project_name\", \"project_github\"]], df_release[[\"project_name\", \"project_github\"]],uniq_dep_adopt,   uniq_dep]).drop_duplicates().shape[0]\n",
    "\n",
    "    print \"\\nAll initial sample\",no_total\n",
    "    general_df.append([lang_, no_total, no_pub, no_gh])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_stats = pd.DataFrame.from_records(general_df,columns=[\"lang\", \"total\", \"published\",\"github\"])\n",
    "print general_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#eg_evo, ver_evo = dafp.get_evo_data(lang)\n",
    "summary_df = []\n",
    "\n",
    "for lang in LANG_ORDER:\n",
    "    lang_ = lang.replace(\"MergedCl\",\"\").replace(\"Cl\",\"\")\n",
    "    (df_fixed, df_adoption, df_release) =   DATASETS[lang] \n",
    "\n",
    "    print \"\\nLang\", lang\n",
    "\n",
    "    rename_rules = {\"adopted_name\":\"project_name\", \"adopted_github\":\"project_github\"}\n",
    "\n",
    "    funcs =  [np.min, percentile(5), np.mean, np.median,percentile(95),np.max  ]\n",
    "    lbls = [\"min\",\"5p\",\"mean\",\"median\",\"95p\",\"max\"]\n",
    "\n",
    "    vers1 =  df_fixed[[\"project_name\", \"project_github\", \"adopted_github\", \"adopted_ver\"]].groupby([\"project_github\",  \"adopted_github\"]).agg({\"adopted_ver\":lambda x: len(x.unique())}).reset_index()\n",
    "    implicit = [fn(vers1[\"adopted_ver\"].values) for fn in funcs]\n",
    "    vers1 =  df_fixed[[\"project_name\", \"project_github\", \"adopted_github\", \"orig_ver_string\"]].groupby([ \"project_github\",  \"adopted_github\"]).agg({\"orig_ver_string\":lambda x: len(x.unique())}).reset_index()\n",
    "    explicit = [fn(vers1[\"orig_ver_string\"].values) for fn in funcs]\n",
    "\n",
    "    df_stats =  pd.DataFrame({\"label\":lbls, \"implicit\":implicit, \"explicit\":explicit})\n",
    "    df_stats.loc[:,\"lang\"] = lang_\n",
    "    summary_df.append(df_stats)\n",
    "    print df_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updates_df = pd.concat(summary_df)\n",
    "updates_df.to_csv(config.FIGURES+\"update_counts.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivoted = pd.pivot_table(updates_df, index=\"lang\", columns=\"label\")\n",
    "\n",
    "print pivoted\n",
    "mi = pd.MultiIndex.from_product([['explicit', 'implicit'], ['min','5p','median','mean', '95p','max']])\n",
    "pivoted_order = pivoted.reindex_axis(mi, 1)\n",
    "\n",
    "with open(config.FIGURES+\"update.tex\",\"w\") as fp:\n",
    "    fp.write(pivoted_order.to_latex(float_format='%.2f'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = pd.pivot_table(pd.melt(updates_df,id_vars=[\"lang\",\"label\"]), index=[\"variable\",\"lang\"], columns=\"label\")\n",
    "mi2 = pd.MultiIndex.from_product([['value'], ['min','5p','median','mean', '95p','max']])\n",
    "stacked = stacked.reindex_axis(mi2,1)\n",
    "stacked\n",
    "with open(config.FIGURES+\"update_stacked.tex\",\"w\") as fp:\n",
    "    fp.write(stacked.to_latex(float_format='%.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOTAL GRAPH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for lang_ in LANG_ORDER:\n",
    "    lang = clean_lang(lang_)\n",
    "    re, ve = dafp.get_evo_data(lang)\n",
    "    last_v =  re.sort_values(\"date\").tail(1)[[\"nodes\",\"unique_relations\",\"github_nodes\",\"published_nodes\"]]\n",
    "    last_v = last_v.rename(columns={\"nodes\":\"projects\",\"unique_relations\":\"project_depedencies\"})\n",
    "    last_r = ve.sort_values(\"date\").tail(1)[[\"nodes\",\"version_relations\"]]\n",
    "    last_r = last_r.rename(columns={\"nodes\":\"releases\",\"version_relations\":\"release_dependencies\"})\n",
    "    \n",
    "    row =  pd.concat((last_v, last_r), axis=1)\n",
    "    if lang == \"Rust\":\n",
    "        row.loc[:,\"published_nodes\"] = row.loc[:,\"projects\"]\n",
    "        row.loc[:,\"github_nodes\"] = 0\n",
    "    row.loc[:,\"lang\"] = lang\n",
    "    rows.append(row)\n",
    "    \n",
    "totals = pd.concat(rows).set_index(\"lang\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print totals\n",
    "print general_stats\n",
    "totals2 = pd.merge(totals, general_stats.set_index(\"lang\")[[\"github\",\"published\"]], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ltable = (totals2*1.0).to_latex(float_format=lambda x:  '{:,.0f}'.format(x))\n",
    "print ltable\n",
    "\n",
    "with open(config.TABLES+\"general_stat.tex\",\"w\") as fp:\n",
    "    fp.write(ltable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print totals.project_depedencies / totals.projects\n",
    "print totals.release_dependencies / totals.releases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MONTH STATS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_reg = pd.read_csv(config.FIGURES+\"last_month_data_reg.csv.gz\")\n",
    "final_ver = pd.read_csv(config.FIGURES+\"last_month_data_ver.csv.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_reg[[\"outdegree\", \"indegree\",\"dependencies_unique\", \"dependents_unique\", \"lang\",\"dependencies_unique_direct\",\"dependents_unique_direct\"]].groupby(\"lang\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ver[[\"lang\",\"indegree\"]].groupby(\"lang\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_ver.lang.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
